import LeanCourse.Common
import Mathlib.Analysis.SpecialFunctions.Trigonometric.Deriv
import Mathlib.Analysis.Calculus.Deriv.Prod
import Mathlib.Analysis.Calculus.Deriv.Pow
open BigOperators Function Set Real Topology
noncomputable section
set_option linter.unusedVariables false
local macro_rules | `($x ^ $y) => `(HPow.hPow $x $y)


/- # Today: Differential Calculus

We cover chapter 10 from Mathematics in Lean. -/

/-
Last time we discussed topology.
-/


/- We write `deriv` to compute the derivative of a function.
`simp` can compute the derivatives of standard functions. -/

example (x : â„) : deriv Real.sin x = Real.cos x := by simp

example (x : â„‚) :
    deriv (fun y â†¦ Complex.sin (y + 3)) x = Complex.cos (x + 3) := by simp

/- Not every function has a derivative. As usual, in mathlib we just define the derivative of a non-differentiable function to be `0`. -/

variable (f : â„ â†’ â„) (x : â„) in
#check (deriv_zero_of_not_differentiableAt :
  Â¬ DifferentiableAt â„ f x â†’ deriv f x = 0)

/- So proving that `deriv f x = y` doesn't necessarily mean that `f` is differentiable.
Often it is nicer to use the predicate `HasDerivAt f y x`, which states that `f`
is differentiable and `f'(x) = y`. -/

example (x : â„) : HasDerivAt Real.sin (Real.cos x) x := by exact hasDerivAt_sin x

/- We can also specify that a function has a derivative without specifying its
derivative. -/

example (x : â„) : DifferentiableAt â„ sin x :=
  (hasDerivAt_sin x).differentiableAt

/- Each of these has their own lemmas. -/

#check HasDerivAt.add
#check deriv_add
#check DifferentiableAt.add


example (x : â„) :
    HasDerivAt (fun x â†¦ Real.cos x + Real.sin x)
    (Real.cos x - Real.sin x) x := by
      rw [sub_eq_neg_add]
      apply HasDerivAt.add
      exact hasDerivAt_cos x
      exact hasDerivAt_sin x






/- We can also take the derivative of functions that take values in a
(normed) vector space. -/

example (x : â„) : deriv (fun x â†¦ ((Real.cos x) ^ 2, (Real.sin x) ^ 2)) x =
    (- 2 * Real.cos x * Real.sin x, 2 * Real.sin x * Real.cos x) := by
    sorry

/-
Lean has the following names for intervals
("c" = closed, "o" = open, "i" = infinity)
Icc a b = [a, b]
Ico a b = [a, b)
Ioc a b = (a, b]
Ioo a b = (a, b)
Ici a   = [a, âˆ)
Ioi a   = (a, âˆ)
Iic b   = (-âˆ, b]
Iio b   = (-âˆ, b)

The intermediate value theorem states that if `f` is continuous and
`f a â‰¤ y â‰¤ f b`, then there is an `x âˆˆ [a, b]` with `f(x) = y`.
-/

example {f : â„ â†’ â„} {a b y : â„} (hab : a â‰¤ b) (hf : ContinuousOn f (Icc a b)) :
    Icc (f a) (f b) âŠ† f '' Icc a b :=
  intermediate_value_Icc hab hf
-- Note that we only require `f` to be continuous on `[a, b]`


/-
The mean value theorem states that if `f` is continuus on `[a, b]`
and differentiable on `(a, b)` then there is a `c âˆˆ (a, b)` where `f'(c)` is the
average slope of `f` on `[a, b]`
-/

example (f : â„ â†’ â„) {a b : â„} (hab : a < b)
    (hf : ContinuousOn f (Icc a b))
    (hf' : DifferentiableOn â„ f (Ioo a b)) :
    âˆƒ c âˆˆ Ioo a b, deriv f c = (f b - f a) / (b - a) :=
  exists_deriv_eq_slope f hab hf hf'


/- Rolle's theorem is the special case where `f a = f b`.
Why is there no differentiability requirement on `f` here? -/
example {f : â„ â†’ â„} {a b : â„} (hab : a < b)
    (hfc : ContinuousOn f (Icc a b)) (hfI : f a = f b) :
    âˆƒ c âˆˆ Ioo a b, deriv f c = 0 :=
  exists_deriv_eq_zero hab hfc hfI



/- For multivariate functions, we have a different notion of derivative.
We can generalize the notion of derivative to normed spaces.

A *normed group* is an abelian group with a norm satisfying the following rules.
-/

section NormedGroup

variable {E : Type*} [NormedAddCommGroup E]

#check (norm : E â†’ â„)

example (x : E) : 0 â‰¤ â€–xâ€– :=
  norm_nonneg x

example {x : E} : â€–xâ€– = 0 â†” x = 0 :=
  norm_eq_zero

example (x y : E) : â€–x + yâ€– â‰¤ â€–xâ€– + â€–yâ€– :=
  norm_add_le x y

/- This turns `E` into a metric space. -/
example (x y : E) : dist x y = â€–x - yâ€– :=
  dist_eq_norm x y

/- A *normed space* is a normed group that is a vector space
satisfying the following condition. -/

variable [NormedSpace â„ E]

example (a : â„) (x : E) : â€–a â€¢ xâ€– = |a| * â€–xâ€– :=
  norm_smul a x


/- A complete normed space is known as a *Banach space*. Every finite-dimensional vector space is complete. -/

example [FiniteDimensional â„ E] : CompleteSpace E := by infer_instance

/- In the above examples, we could also replace `â„` by `â„‚`
or another *normed field*. -/

end NormedGroup

/- Morphisms between normed spaces are continuous linear maps `E â†’L[ğ•œ] F`. -/
section NormedSpace

variable {ğ•œ : Type*} [NontriviallyNormedField ğ•œ]
  {E : Type*} [NormedAddCommGroup E] [NormedSpace ğ•œ E]
  {F : Type*} [NormedAddCommGroup F] [NormedSpace ğ•œ F]


example : E â†’L[ğ•œ] E := ContinuousLinearMap.id ğ•œ E

example (f : E â†’L[ğ•œ] F) : E â†’ F := f

example (f : E â†’L[ğ•œ] F) : Continuous f := f.cont

example (f : E â†’L[ğ•œ] F) : E â†’â‚—[ğ•œ] F := f

/- Continuous linear maps have an operator norm. -/

example (f : E â†’L[ğ•œ] F) (x : E) : â€–f xâ€– â‰¤ â€–fâ€– * â€–xâ€– :=
  f.le_op_norm x

example (f : E â†’L[ğ•œ] F) {M : â„} (hMp : 0 â‰¤ M)
    (hM : âˆ€ x, â€–f xâ€– â‰¤ M * â€–xâ€–) : â€–fâ€– â‰¤ M :=
  f.op_norm_le_bound hMp hM


/- Defining differentiability requires asymptotic comparisons. -/

section Asymptotics
open Asymptotics

variable {Î± : Type*} (l : Filter Î±) (f : Î± â†’ E) (g : Î± â†’ F)

example (c : â„) : IsBigOWith c l f g â†” âˆ€á¶  x in l, â€–f xâ€– â‰¤ c * â€–g xâ€– :=
  isBigOWith_iff

example : f =O[l] g â†” âˆƒ C, IsBigOWith C l f g :=
  isBigO_iff_isBigOWith

example : f =o[l] g â†” âˆ€ C > 0, IsBigOWith C l f g :=
  isLittleO_iff_forall_isBigOWith

end Asymptotics

/- We define the *FrÃ©chet derivative* of any function between normed spaces. -/

example (f : E â†’ F) (f' : E â†’L[ğ•œ] F) (xâ‚€ : E) :
    HasFDerivAt f f' xâ‚€ â†”
    (fun x â†¦ f x - f xâ‚€ - f' (x - xâ‚€)) =o[ğ“ xâ‚€] fun x â†¦ x - xâ‚€ := by
  rfl

example (f : E â†’ F) (f' : E â†’L[ğ•œ] F) (xâ‚€ : E) (hff' : HasFDerivAt f f' xâ‚€) :
    fderiv ğ•œ f xâ‚€ = f' :=
  hff'.fderiv

/- We write `ContDiff ğ•œ n f` to say that `f` is `C^n`, i.e. it is
  `n`-times continuously differentiable.
  Here `n` lives in `â„•âˆ`, which is `â„•` with an extra top element `âŠ¤` added ("âˆ"). -/

variable {f g : E â†’ F} {n : â„•âˆ}
example (hf : ContDiff ğ•œ n f) (hg : ContDiff ğ•œ n g) :
    ContDiff ğ•œ n (fun x â†¦ (f x, 2 â€¢ f x + g x)) := by sorry

example : ContDiff ğ•œ 0 f â†” Continuous f := contDiff_zero

example {n : â„•} : ContDiff ğ•œ (n+1) f â†”
  Differentiable ğ•œ f âˆ§ ContDiff ğ•œ n (fderiv ğ•œ f) := contDiff_succ_iff_fderiv

example : ContDiff ğ•œ âŠ¤ f â†” âˆ€ n : â„•, ContDiff ğ•œ n f := contDiff_top

end NormedSpace



/- # Exercises -/

example (x : â„) :
    deriv (fun x â†¦ Real.exp (x ^ 2)) x = 2 * x * Real.exp (x ^ 2) := by
      simp
      ring

/- If you have a continuous injective function `â„ â†’ â„` then `f` is monotone or antitone. This is a possible first step in proving that result.
Prove this by contradiction using the intermediate value theorem. -/
example {f : â„ â†’ â„} (hf : Continuous f) {a b x : â„} (hab : a â‰¤ b) : ContinuousOn f (Icc a b) := by exact Continuous.continuousOn hf

example {f : â„ â†’ â„} (hf : Continuous f) {a b x : â„} (hab : a â‰¤ b) (h' : x âˆˆ Icc a b) : f x âˆˆ f '' Icc a b := by exact mem_image_of_mem f h'

example {a b x : â„} (hab : a â‰¤ b) (hx : x < a) :  x âˆ‰ Icc a b := by exact not_mem_Icc_of_lt hx

example {a b x : â„} (hab : a â‰¤ b) (hx : x âˆˆ Icc a b) :  x â‰¤ b := by exact hx.2

example {a b x : â„} {U V : Set â„} (ha : a âˆ‰ V) (hUV : U âŠ† V) : a âˆ‰ U := by exact not_mem_subset hUV ha

example {a b x : â„} (hab : a < b) :  a â‰¤ b  := by exact LT.lt.le hab

example {f : â„ â†’ â„} (hf : Continuous f) (h2f : Injective f) {a b x : â„}
    (hab : a â‰¤ b) (h2ab : f a < f b) (hx : x âˆˆ Icc a b) : f a â‰¤ f x := by
      by_contra h
      push_neg at h
      -- have : Icc (f a) (f b) âŠ† f '' Icc a b := intermediate_value_Icc hab (Continuous.continuousOn hf)
      -- specialize this (mem_image_of_mem f hx)
      have : Icc (f x) (f b) âŠ† f '' Icc x b := intermediate_value_Icc hx.2 (Continuous.continuousOn hf)
      specialize this âŸ¨LT.lt.le h, LT.lt.le h2abâŸ©
      obtain âŸ¨x', hx'1, hx'2âŸ© := this
      specialize h2f hx'2
      rw [h2f] at hx'1
      have : x = a := by apply le_antisymm hx'1.1 hx.1
      rw [this] at h
      linarith


variable {ğ•œ : Type*} [NontriviallyNormedField ğ•œ]
  {E : Type*} [NormedAddCommGroup E] [NormedSpace ğ•œ E]
  {n : â„•âˆ}

example (f g : E â†’ E) (hf : ContDiff ğ•œ n f) (hg : ContDiff ğ•œ n g) : ContDiff ğ•œ n (fun z : E Ã— E â†¦ f z.1) := by exact ContDiff.fst' hf

example (f g : E â†’ E) (hf : ContDiff ğ•œ n f) (hg : ContDiff ğ•œ n g) : ContDiff ğ•œ n (f âˆ˜ g) := by exact ContDiff.comp hf hg

example (L : E â†’L[ğ•œ] E â†’L[ğ•œ] E) :ContDiff ğ•œ n (fun z : E Ã— E â†¦ L z.1 z.2) := by
 apply IsBoundedBilinearMap.contDiff
 exact ContinuousLinearMap.isBoundedBilinearMap L

/- In this exercise you should combine the right lemmas from the library, in particular `IsBoundedBilinearMap.contDiff`. -/
example (L : E â†’L[ğ•œ] E â†’L[ğ•œ] E) (f g : E â†’ E) (hf : ContDiff ğ•œ n f)
    (hg : ContDiff ğ•œ n g) :
    ContDiff ğ•œ n (fun z : E Ã— E â†¦ L (f z.1) (g z.2)) := by
    have : (fun z : E Ã— E â†¦ L (f z.1) (g z.2)) = (fun z : E Ã— E â†¦ L z.1 z.2) âˆ˜ (fun z : E Ã— E â†¦ (f z.1, g z.2)) := by ext; simp;
    rw [this]
    apply ContDiff.comp _ _
    . apply IsBoundedBilinearMap.contDiff
      exact ContinuousLinearMap.isBoundedBilinearMap L
    . apply ContDiff.prod
      . exact ContDiff.fst' hf
      . exact ContDiff.snd' hg



#check ContDiff.prod
#check ContDiff.prod_map
#check IsBoundedBilinearMap.contDiff
#check IsBoundedBilinearMap
#check ContDiff.comp
/- If you finish these exercises, continue with the exercises of lecture 11. -/
